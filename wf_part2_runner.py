#!/usr/bin/env python
# wf_part2_runner 0.0.1
# Generated by dx-app-wizard.
#
# Basic execution pattern: Your app will run on a single machine from
# beginning to end.
#
# See https://documentation.dnanexus.com/developer for documentation and
# tutorials on how to modify this file.
#
# DNAnexus Python Bindings (dxpy) documentation:
#   http://autodoc.dnanexus.com/bindings/python/current/

import os
import dxpy
import sys
import os
sys.path.append("/")
print ("DIR: /", os.listdir("/"))


import modules.workflow_wrappers.wf_wrappers as wfw

@dxpy.entry_point('main')
def main(project_id, output_folder, workflow_name, run_name, panel, instrument, target_interval_list,
         target_interval_list_bp_resolution, bait_interval_list,remove_duplicate_reads,fastq_subgroups):
    output_project = dxpy.DXProject(project_id)

    print("output_folder", output_folder)
    print ("fastq_subgroups: ", fastq_subgroups)
    output_folder_run_name = "%s/%s" % (output_folder, run_name)
    print(output_folder_run_name)
    demux_folder_list = output_project.list_folder("%s/Demultiplex/" % (output_folder_run_name), describe=True)
    print (demux_folder_list)
    fastqs_list_of_lists = []
    if panel == 'large':
        number_per_list = 16
    elif panel == 'small':
        number_per_list = 32
    else:
        number_per_list = 16
    counter = 0
    fastqs = []
    all_fastqs_dict = {}
    for obj in demux_folder_list['objects']:
        filename = (obj['describe']['name'])
        if ('_R1_' in filename or '_R2_' in filename) and 'Undetermined' not in filename and 'NTC' not in filename:
            all_fastqs_dict[filename] = obj['id']
        else:
            print ("EXCLUDE: ", filename)
    print ("Number of fastqs: ",len(all_fastqs_dict))
    for filename in sorted(list(all_fastqs_dict.keys())):
        fastqs.append(all_fastqs_dict[filename])
        if len(fastqs) == number_per_list:
            print("\n".join(fastqs))
            fastqs_list_of_lists.append(fastqs)
            fastqs = []
    if len(fastqs) > 0:
        fastqs_list_of_lists.append(fastqs)
    print(fastqs_list_of_lists)
    counter_2 = 0
    for x in fastqs_list_of_lists:
        counter_2 += 1
        print(len(x), counter_2)
    job_counter = 0
    job_list = []
    wf_list = []
    new_fastqs_list_of_lists = []
    if fastq_subgroups == 'ALL':
        new_fastqs_list_of_lists = fastqs_list_of_lists

    else:
        fastq_subgroups = fastq_subgroups.split(",")
        for n in fastq_subgroups:
            new_fastqs_list_of_lists.append(fastqs_list_of_lists[int(n)-1])

    for n in list(range(len(new_fastqs_list_of_lists))):
        fastqs_list = new_fastqs_list_of_lists[n]
        if fastq_subgroups == 'ALL':
            job_counter += 1
        else:
            job_counter = fastq_subgroups[n]

        print("\n")
        print("*" * 100)
        print("GROUP %s" % (job_counter))
        wf = dxpy.new_dxworkflow(title="%s: %s PART2 %s" % (workflow_name, run_name, job_counter),
                                 name="%s: %s PART2 %s" % (workflow_name, run_name, job_counter),
                                 description="%s: %s PART2 %s" % (workflow_name, run_name, job_counter),
                                 project=project_id,
                                 folder="%s/%s" % (output_folder, run_name),
                                 )
        print(fastqs_list)
        wfw.fastqtrimmer(wf, fastqs_list)
        wfw.novoalign_and_sort(wf)
        wfw.markedduplicates(wf,remove_duplicate_reads)
        wfw.BAMPostProcess(wf)
        wfw.collectmultiplemetrics(wf, target_interval_list, bait_interval_list)
        wfw.variant_discovery(wf, target_interval_list)
        wfw.variant_discovery_bp_resolution(wf, target_interval_list_bp_resolution)
        wfw.adjusted_base_count_analysis(wf, target_interval_list)
        wfw.add_abc_to_vcf(wf)
        wfw.custom_caller(wf)
        wfw.vcf_annotate2(wf, instrument)
        #wfw.qci_link_sql_dx(wf)
        #wfw.evm(wf, instrument)



        wf.close()

        wf_list.append(wf.id)

        workflowHandler = dxpy.DXWorkflow(wf.id)
        workflow_part2_run = workflowHandler.run(workflow_input={}, project=project_id,
                                                 folder="/",
                                                name="%s: %s PART2 %s" % (workflow_name, run_name, job_counter),
                                               delay_workspace_destruction=False)

        job = (workflow_part2_run.get_id())
        job_list.append(job)


        print("dxpy.WORKSPACE_ID(): ", dxpy.WORKSPACE_ID)
        container_id = dxpy.WORKSPACE_ID



        wf = dxpy.new_dxworkflow(title="%s: %s PART2 %s clone" % (workflow_name, run_name,job_counter),
                                 name="%s: %s PART2 %s clone" % (workflow_name, run_name,job_counter),
                                 description="%s: %s PART2 %s clone" % (workflow_name, run_name,job_counter),
                                 project=project_id,
                                 folder="%s/%s" % (output_folder, run_name))


        wfw.clone_data(wf, container_id, project_id, output_folder, run_name)
        wf.close()
        workflowHandler = dxpy.DXWorkflow(wf.id)
        workflow_part3_run = workflowHandler.run(workflow_input={}, project=project_id,
                                                 folder="/",
                                                 name="%s: %s PART2 %s clone" % (workflow_name, run_name,job_counter),
                                                 depends_on=[job],
                                                 delay_workspace_destruction=False)





    output = {}
    output["wf_list"] = wf_list



    return output

dxpy.run()
